{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    \"\"\"\n",
    "        Normalize the array X\n",
    "    \"\"\"\n",
    "    mean = np.mean(X)\n",
    "    std = np.std(X)\n",
    "    X = (X - mean) / std\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-f329c4b3246f>:2: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\__init__.py:80: load_boston (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use scikits.learn.datasets.\n",
      "WARNING:tensorflow:From C:\\Users\\hdc\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:129: load_csv_with_header (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data instead.\n",
      "X_train:  [[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]] X_train's shape:  (506, 13) \n",
      "Y_train:  [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9] Y_train's shape:  (506,)\n"
     ]
    }
   ],
   "source": [
    "# Data \n",
    "boston = tf.contrib.learn.datasets.load_dataset('boston')\n",
    "X_train, Y_train = boston.data, boston.target\n",
    "print('X_train: ', X_train, 'X_train\\'s shape: ', X_train.shape, '\\nY_train: ', Y_train, 'Y_train\\'s shape: ', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加上一条偏置项bias， Y = x_0 + a1*x_1 + a2_x2 +...+an*x_n\n",
    "def append_bias_reshape(features, labels):\n",
    "    m = features.shape[0]\n",
    "    n = features.shape[1]\n",
    "#     print(np.c_[np.ones(m), features], np.c_[np.ones(m), features].shape)\n",
    "    x = np.reshape(np.c_[np.ones(m), features], [m, n+1])\n",
    "    y = np.reshape(labels, [m, 1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  [[ 1.         -0.48269464 -0.35873385 ... -0.3773345   2.25155745\n",
      "  -0.44843032]\n",
      " [ 1.         -0.48255004 -0.48273818 ... -0.36011167  2.25155745\n",
      "  -0.41977154]\n",
      " [ 1.         -0.48255018 -0.48273818 ... -0.36011167  2.22351869\n",
      "  -0.45497499]\n",
      " ...\n",
      " [ 1.         -0.4823196  -0.48273818 ... -0.33806646  2.25155745\n",
      "  -0.44388349]\n",
      " [ 1.         -0.4819832  -0.48273818 ... -0.33806646  2.22778995\n",
      "  -0.43809662]\n",
      " [ 1.         -0.48241157 -0.48273818 ... -0.33806646  2.25155745\n",
      "  -0.42845184]] X_train's shape:  (506, 14) \n",
      "Y_train:  [[24. ]\n",
      " [21.6]\n",
      " [34.7]\n",
      " [33.4]\n",
      " [36.2]\n",
      " [28.7]\n",
      " [22.9]\n",
      " [27.1]\n",
      " [16.5]\n",
      " [18.9]\n",
      " [15. ]\n",
      " [18.9]\n",
      " [21.7]\n",
      " [20.4]\n",
      " [18.2]\n",
      " [19.9]\n",
      " [23.1]\n",
      " [17.5]\n",
      " [20.2]\n",
      " [18.2]\n",
      " [13.6]\n",
      " [19.6]\n",
      " [15.2]\n",
      " [14.5]\n",
      " [15.6]\n",
      " [13.9]\n",
      " [16.6]\n",
      " [14.8]\n",
      " [18.4]\n",
      " [21. ]\n",
      " [12.7]\n",
      " [14.5]\n",
      " [13.2]\n",
      " [13.1]\n",
      " [13.5]\n",
      " [18.9]\n",
      " [20. ]\n",
      " [21. ]\n",
      " [24.7]\n",
      " [30.8]\n",
      " [34.9]\n",
      " [26.6]\n",
      " [25.3]\n",
      " [24.7]\n",
      " [21.2]\n",
      " [19.3]\n",
      " [20. ]\n",
      " [16.6]\n",
      " [14.4]\n",
      " [19.4]\n",
      " [19.7]\n",
      " [20.5]\n",
      " [25. ]\n",
      " [23.4]\n",
      " [18.9]\n",
      " [35.4]\n",
      " [24.7]\n",
      " [31.6]\n",
      " [23.3]\n",
      " [19.6]\n",
      " [18.7]\n",
      " [16. ]\n",
      " [22.2]\n",
      " [25. ]\n",
      " [33. ]\n",
      " [23.5]\n",
      " [19.4]\n",
      " [22. ]\n",
      " [17.4]\n",
      " [20.9]\n",
      " [24.2]\n",
      " [21.7]\n",
      " [22.8]\n",
      " [23.4]\n",
      " [24.1]\n",
      " [21.4]\n",
      " [20. ]\n",
      " [20.8]\n",
      " [21.2]\n",
      " [20.3]\n",
      " [28. ]\n",
      " [23.9]\n",
      " [24.8]\n",
      " [22.9]\n",
      " [23.9]\n",
      " [26.6]\n",
      " [22.5]\n",
      " [22.2]\n",
      " [23.6]\n",
      " [28.7]\n",
      " [22.6]\n",
      " [22. ]\n",
      " [22.9]\n",
      " [25. ]\n",
      " [20.6]\n",
      " [28.4]\n",
      " [21.4]\n",
      " [38.7]\n",
      " [43.8]\n",
      " [33.2]\n",
      " [27.5]\n",
      " [26.5]\n",
      " [18.6]\n",
      " [19.3]\n",
      " [20.1]\n",
      " [19.5]\n",
      " [19.5]\n",
      " [20.4]\n",
      " [19.8]\n",
      " [19.4]\n",
      " [21.7]\n",
      " [22.8]\n",
      " [18.8]\n",
      " [18.7]\n",
      " [18.5]\n",
      " [18.3]\n",
      " [21.2]\n",
      " [19.2]\n",
      " [20.4]\n",
      " [19.3]\n",
      " [22. ]\n",
      " [20.3]\n",
      " [20.5]\n",
      " [17.3]\n",
      " [18.8]\n",
      " [21.4]\n",
      " [15.7]\n",
      " [16.2]\n",
      " [18. ]\n",
      " [14.3]\n",
      " [19.2]\n",
      " [19.6]\n",
      " [23. ]\n",
      " [18.4]\n",
      " [15.6]\n",
      " [18.1]\n",
      " [17.4]\n",
      " [17.1]\n",
      " [13.3]\n",
      " [17.8]\n",
      " [14. ]\n",
      " [14.4]\n",
      " [13.4]\n",
      " [15.6]\n",
      " [11.8]\n",
      " [13.8]\n",
      " [15.6]\n",
      " [14.6]\n",
      " [17.8]\n",
      " [15.4]\n",
      " [21.5]\n",
      " [19.6]\n",
      " [15.3]\n",
      " [19.4]\n",
      " [17. ]\n",
      " [15.6]\n",
      " [13.1]\n",
      " [41.3]\n",
      " [24.3]\n",
      " [23.3]\n",
      " [27. ]\n",
      " [50. ]\n",
      " [50. ]\n",
      " [50. ]\n",
      " [22.7]\n",
      " [25. ]\n",
      " [50. ]\n",
      " [23.8]\n",
      " [23.8]\n",
      " [22.3]\n",
      " [17.4]\n",
      " [19.1]\n",
      " [23.1]\n",
      " [23.6]\n",
      " [22.6]\n",
      " [29.4]\n",
      " [23.2]\n",
      " [24.6]\n",
      " [29.9]\n",
      " [37.2]\n",
      " [39.8]\n",
      " [36.2]\n",
      " [37.9]\n",
      " [32.5]\n",
      " [26.4]\n",
      " [29.6]\n",
      " [50. ]\n",
      " [32. ]\n",
      " [29.8]\n",
      " [34.9]\n",
      " [37. ]\n",
      " [30.5]\n",
      " [36.4]\n",
      " [31.1]\n",
      " [29.1]\n",
      " [50. ]\n",
      " [33.3]\n",
      " [30.3]\n",
      " [34.6]\n",
      " [34.9]\n",
      " [32.9]\n",
      " [24.1]\n",
      " [42.3]\n",
      " [48.5]\n",
      " [50. ]\n",
      " [22.6]\n",
      " [24.4]\n",
      " [22.5]\n",
      " [24.4]\n",
      " [20. ]\n",
      " [21.7]\n",
      " [19.3]\n",
      " [22.4]\n",
      " [28.1]\n",
      " [23.7]\n",
      " [25. ]\n",
      " [23.3]\n",
      " [28.7]\n",
      " [21.5]\n",
      " [23. ]\n",
      " [26.7]\n",
      " [21.7]\n",
      " [27.5]\n",
      " [30.1]\n",
      " [44.8]\n",
      " [50. ]\n",
      " [37.6]\n",
      " [31.6]\n",
      " [46.7]\n",
      " [31.5]\n",
      " [24.3]\n",
      " [31.7]\n",
      " [41.7]\n",
      " [48.3]\n",
      " [29. ]\n",
      " [24. ]\n",
      " [25.1]\n",
      " [31.5]\n",
      " [23.7]\n",
      " [23.3]\n",
      " [22. ]\n",
      " [20.1]\n",
      " [22.2]\n",
      " [23.7]\n",
      " [17.6]\n",
      " [18.5]\n",
      " [24.3]\n",
      " [20.5]\n",
      " [24.5]\n",
      " [26.2]\n",
      " [24.4]\n",
      " [24.8]\n",
      " [29.6]\n",
      " [42.8]\n",
      " [21.9]\n",
      " [20.9]\n",
      " [44. ]\n",
      " [50. ]\n",
      " [36. ]\n",
      " [30.1]\n",
      " [33.8]\n",
      " [43.1]\n",
      " [48.8]\n",
      " [31. ]\n",
      " [36.5]\n",
      " [22.8]\n",
      " [30.7]\n",
      " [50. ]\n",
      " [43.5]\n",
      " [20.7]\n",
      " [21.1]\n",
      " [25.2]\n",
      " [24.4]\n",
      " [35.2]\n",
      " [32.4]\n",
      " [32. ]\n",
      " [33.2]\n",
      " [33.1]\n",
      " [29.1]\n",
      " [35.1]\n",
      " [45.4]\n",
      " [35.4]\n",
      " [46. ]\n",
      " [50. ]\n",
      " [32.2]\n",
      " [22. ]\n",
      " [20.1]\n",
      " [23.2]\n",
      " [22.3]\n",
      " [24.8]\n",
      " [28.5]\n",
      " [37.3]\n",
      " [27.9]\n",
      " [23.9]\n",
      " [21.7]\n",
      " [28.6]\n",
      " [27.1]\n",
      " [20.3]\n",
      " [22.5]\n",
      " [29. ]\n",
      " [24.8]\n",
      " [22. ]\n",
      " [26.4]\n",
      " [33.1]\n",
      " [36.1]\n",
      " [28.4]\n",
      " [33.4]\n",
      " [28.2]\n",
      " [22.8]\n",
      " [20.3]\n",
      " [16.1]\n",
      " [22.1]\n",
      " [19.4]\n",
      " [21.6]\n",
      " [23.8]\n",
      " [16.2]\n",
      " [17.8]\n",
      " [19.8]\n",
      " [23.1]\n",
      " [21. ]\n",
      " [23.8]\n",
      " [23.1]\n",
      " [20.4]\n",
      " [18.5]\n",
      " [25. ]\n",
      " [24.6]\n",
      " [23. ]\n",
      " [22.2]\n",
      " [19.3]\n",
      " [22.6]\n",
      " [19.8]\n",
      " [17.1]\n",
      " [19.4]\n",
      " [22.2]\n",
      " [20.7]\n",
      " [21.1]\n",
      " [19.5]\n",
      " [18.5]\n",
      " [20.6]\n",
      " [19. ]\n",
      " [18.7]\n",
      " [32.7]\n",
      " [16.5]\n",
      " [23.9]\n",
      " [31.2]\n",
      " [17.5]\n",
      " [17.2]\n",
      " [23.1]\n",
      " [24.5]\n",
      " [26.6]\n",
      " [22.9]\n",
      " [24.1]\n",
      " [18.6]\n",
      " [30.1]\n",
      " [18.2]\n",
      " [20.6]\n",
      " [17.8]\n",
      " [21.7]\n",
      " [22.7]\n",
      " [22.6]\n",
      " [25. ]\n",
      " [19.9]\n",
      " [20.8]\n",
      " [16.8]\n",
      " [21.9]\n",
      " [27.5]\n",
      " [21.9]\n",
      " [23.1]\n",
      " [50. ]\n",
      " [50. ]\n",
      " [50. ]\n",
      " [50. ]\n",
      " [50. ]\n",
      " [13.8]\n",
      " [13.8]\n",
      " [15. ]\n",
      " [13.9]\n",
      " [13.3]\n",
      " [13.1]\n",
      " [10.2]\n",
      " [10.4]\n",
      " [10.9]\n",
      " [11.3]\n",
      " [12.3]\n",
      " [ 8.8]\n",
      " [ 7.2]\n",
      " [10.5]\n",
      " [ 7.4]\n",
      " [10.2]\n",
      " [11.5]\n",
      " [15.1]\n",
      " [23.2]\n",
      " [ 9.7]\n",
      " [13.8]\n",
      " [12.7]\n",
      " [13.1]\n",
      " [12.5]\n",
      " [ 8.5]\n",
      " [ 5. ]\n",
      " [ 6.3]\n",
      " [ 5.6]\n",
      " [ 7.2]\n",
      " [12.1]\n",
      " [ 8.3]\n",
      " [ 8.5]\n",
      " [ 5. ]\n",
      " [11.9]\n",
      " [27.9]\n",
      " [17.2]\n",
      " [27.5]\n",
      " [15. ]\n",
      " [17.2]\n",
      " [17.9]\n",
      " [16.3]\n",
      " [ 7. ]\n",
      " [ 7.2]\n",
      " [ 7.5]\n",
      " [10.4]\n",
      " [ 8.8]\n",
      " [ 8.4]\n",
      " [16.7]\n",
      " [14.2]\n",
      " [20.8]\n",
      " [13.4]\n",
      " [11.7]\n",
      " [ 8.3]\n",
      " [10.2]\n",
      " [10.9]\n",
      " [11. ]\n",
      " [ 9.5]\n",
      " [14.5]\n",
      " [14.1]\n",
      " [16.1]\n",
      " [14.3]\n",
      " [11.7]\n",
      " [13.4]\n",
      " [ 9.6]\n",
      " [ 8.7]\n",
      " [ 8.4]\n",
      " [12.8]\n",
      " [10.5]\n",
      " [17.1]\n",
      " [18.4]\n",
      " [15.4]\n",
      " [10.8]\n",
      " [11.8]\n",
      " [14.9]\n",
      " [12.6]\n",
      " [14.1]\n",
      " [13. ]\n",
      " [13.4]\n",
      " [15.2]\n",
      " [16.1]\n",
      " [17.8]\n",
      " [14.9]\n",
      " [14.1]\n",
      " [12.7]\n",
      " [13.5]\n",
      " [14.9]\n",
      " [20. ]\n",
      " [16.4]\n",
      " [17.7]\n",
      " [19.5]\n",
      " [20.2]\n",
      " [21.4]\n",
      " [19.9]\n",
      " [19. ]\n",
      " [19.1]\n",
      " [19.1]\n",
      " [20.1]\n",
      " [19.9]\n",
      " [19.6]\n",
      " [23.2]\n",
      " [29.8]\n",
      " [13.8]\n",
      " [13.3]\n",
      " [16.7]\n",
      " [12. ]\n",
      " [14.6]\n",
      " [21.4]\n",
      " [23. ]\n",
      " [23.7]\n",
      " [25. ]\n",
      " [21.8]\n",
      " [20.6]\n",
      " [21.2]\n",
      " [19.1]\n",
      " [20.6]\n",
      " [15.2]\n",
      " [ 7. ]\n",
      " [ 8.1]\n",
      " [13.6]\n",
      " [20.1]\n",
      " [21.8]\n",
      " [24.5]\n",
      " [23.1]\n",
      " [19.7]\n",
      " [18.3]\n",
      " [21.2]\n",
      " [17.5]\n",
      " [16.8]\n",
      " [22.4]\n",
      " [20.6]\n",
      " [23.9]\n",
      " [22. ]\n",
      " [11.9]] Y_train's shape:  (506, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_train, Y_train = append_bias_reshape(X_train, Y_train)\n",
    "print('X_train: ', X_train, 'X_train\\'s shape: ', X_train.shape, '\\nY_train: ', Y_train, 'Y_train\\'s shape: ', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len = X_train.shape[0]\n",
    "feature_num = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "\n",
    "w = tf.Variable(tf.random_normal([feature_num, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'loss_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat = tf.matmul(X, w)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y - Y_hat), name='loss')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n",
    "tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 343.48480224609375\n",
      "Epoch 1: Loss 252.8187713623047\n",
      "Epoch 2: Loss 200.94223022460938\n",
      "Epoch 3: Loss 170.74110412597656\n",
      "Epoch 4: Loss 152.67674255371094\n",
      "Epoch 5: Loss 141.4315643310547\n",
      "Epoch 6: Loss 134.04000854492188\n",
      "Epoch 7: Loss 128.84727478027344\n",
      "Epoch 8: Loss 124.92881774902344\n",
      "Epoch 9: Loss 121.76728057861328\n",
      "Epoch 10: Loss 119.07218933105469\n",
      "Epoch 11: Loss 116.67960357666016\n",
      "Epoch 12: Loss 114.49624633789062\n",
      "Epoch 13: Loss 112.4681625366211\n",
      "Epoch 14: Loss 110.56360626220703\n",
      "Epoch 15: Loss 108.7630615234375\n",
      "Epoch 16: Loss 107.05408477783203\n",
      "Epoch 17: Loss 105.42814636230469\n",
      "Epoch 18: Loss 103.87898254394531\n",
      "Epoch 19: Loss 102.40174865722656\n",
      "Epoch 20: Loss 100.99236297607422\n",
      "Epoch 21: Loss 99.6472396850586\n",
      "Epoch 22: Loss 98.3631591796875\n",
      "Epoch 23: Loss 97.13716125488281\n",
      "Epoch 24: Loss 95.96647644042969\n",
      "Epoch 25: Loss 94.84849548339844\n",
      "Epoch 26: Loss 93.78073120117188\n",
      "Epoch 27: Loss 92.76087188720703\n",
      "Epoch 28: Loss 91.78665924072266\n",
      "Epoch 29: Loss 90.85597229003906\n",
      "Epoch 30: Loss 89.96678161621094\n",
      "Epoch 31: Loss 89.11715698242188\n",
      "Epoch 32: Loss 88.30528259277344\n",
      "Epoch 33: Loss 87.52936553955078\n",
      "Epoch 34: Loss 86.78778076171875\n",
      "Epoch 35: Loss 86.07891082763672\n",
      "Epoch 36: Loss 85.40122985839844\n",
      "Epoch 37: Loss 84.75330352783203\n",
      "Epoch 38: Loss 84.13375091552734\n",
      "Epoch 39: Loss 83.54124450683594\n",
      "Epoch 40: Loss 82.97454071044922\n",
      "Epoch 41: Loss 82.43244171142578\n",
      "Epoch 42: Loss 81.913818359375\n",
      "Epoch 43: Loss 81.41753387451172\n",
      "Epoch 44: Loss 80.94261169433594\n",
      "Epoch 45: Loss 80.48802947998047\n",
      "Epoch 46: Loss 80.0528564453125\n",
      "Epoch 47: Loss 79.63617706298828\n",
      "Epoch 48: Loss 79.2371597290039\n",
      "Epoch 49: Loss 78.85497283935547\n",
      "Epoch 50: Loss 78.48883819580078\n",
      "Epoch 51: Loss 78.13803100585938\n",
      "Epoch 52: Loss 77.80181121826172\n",
      "Epoch 53: Loss 77.47952270507812\n",
      "Epoch 54: Loss 77.1705093383789\n",
      "Epoch 55: Loss 76.87419128417969\n",
      "Epoch 56: Loss 76.5899429321289\n",
      "Epoch 57: Loss 76.31720733642578\n",
      "Epoch 58: Loss 76.05548095703125\n",
      "Epoch 59: Loss 75.80425262451172\n",
      "Epoch 60: Loss 75.56304168701172\n",
      "Epoch 61: Loss 75.33135986328125\n",
      "Epoch 62: Loss 75.10877227783203\n",
      "Epoch 63: Loss 74.8948974609375\n",
      "Epoch 64: Loss 74.68928527832031\n",
      "Epoch 65: Loss 74.4915771484375\n",
      "Epoch 66: Loss 74.30142974853516\n",
      "Epoch 67: Loss 74.11846160888672\n",
      "Epoch 68: Loss 73.94236755371094\n",
      "Epoch 69: Loss 73.7728271484375\n",
      "Epoch 70: Loss 73.60953521728516\n",
      "Epoch 71: Loss 73.45220184326172\n",
      "Epoch 72: Loss 73.30057525634766\n",
      "Epoch 73: Loss 73.15437316894531\n",
      "Epoch 74: Loss 73.01333618164062\n",
      "Epoch 75: Loss 72.87725830078125\n",
      "Epoch 76: Loss 72.74591827392578\n",
      "Epoch 77: Loss 72.61906433105469\n",
      "Epoch 78: Loss 72.49652099609375\n",
      "Epoch 79: Loss 72.37808990478516\n",
      "Epoch 80: Loss 72.26355743408203\n",
      "Epoch 81: Loss 72.15278625488281\n",
      "Epoch 82: Loss 72.04557037353516\n",
      "Epoch 83: Loss 71.9417724609375\n",
      "Epoch 84: Loss 71.84123229980469\n",
      "Epoch 85: Loss 71.7437973022461\n",
      "Epoch 86: Loss 71.64933013916016\n",
      "Epoch 87: Loss 71.5577163696289\n",
      "Epoch 88: Loss 71.46878814697266\n",
      "Epoch 89: Loss 71.38246154785156\n",
      "Epoch 90: Loss 71.2986068725586\n",
      "Epoch 91: Loss 71.21710968017578\n",
      "Epoch 92: Loss 71.13786315917969\n",
      "Epoch 93: Loss 71.0607681274414\n",
      "Epoch 94: Loss 70.98574829101562\n",
      "Epoch 95: Loss 70.91268920898438\n",
      "Epoch 96: Loss 70.84150695800781\n",
      "Epoch 97: Loss 70.77212524414062\n",
      "Epoch 98: Loss 70.70446014404297\n",
      "Epoch 99: Loss 70.63844299316406\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    merge_summary_op = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('log/multi_linear_regression', sess.graph)\n",
    "    \n",
    "    for i in range(100):\n",
    "        _, l, summary_str = sess.run([optimizer, loss, merge_summary_op], feed_dict={X: X_train, Y: Y_train})\n",
    "        total.append(l)\n",
    "        print('Epoch {0}: Loss {1}'.format(i, l))\n",
    "        writer.add_summary(summary_str, i)\n",
    "    writer.close()\n",
    "    w_val = sess.run(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
